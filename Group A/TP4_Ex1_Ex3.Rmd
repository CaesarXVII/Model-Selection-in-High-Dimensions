---
title: "TP4"
author: "Group A"
date: "13 de março de 2018"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



To compare the results of TP3 with $rho$=0 with TP with $rho$={0.2 0.5 0.7} we used the corrected R code uploaded in the TP3.

# Results for rho=0:

min(cv_error) = 0.8957

correct model = 17th

min AIC=1487.57

correct model still the 17th

# 3 Criteria to choose the best performance:

* Exact model proportion

CV is not perfect because is selecting also model 28 and 31

pos_CV
   17 28 17 28 28 17 17 17 28 28 28 17 28 17 28 17 28 17 17 17 17 17 17 17 17 28 31 17 31 31 17 28 17 17 28 31 31
  17 31 28 17 17 28 17 31 17 31 28 31 31 17 31 17 17 31 28 17 28 17 31 17 28 17 31 17 31 17 17 28 17 28 17 17 28
  17 28 28 17 31 31 31 17 17 28 17 17 17 17 28 28 28 31 31 17 17 17 28 28 28 17
  
  
sum(pos_CV == "17")/100 #0.5 #0.36  #0.44 #0.45 #large variation

AIC is also not perfect because is selecting model also 26 and 28

pos_AIC
  
   17 17 28 17 17 17 17 17 31 28 17 17 17 17 17 17 17 17 17 17 28 17 26 17 17 17 17 28 17 17 28 17 17 28 17 26 17
  28 17 17 26 28 17 17 17 26 26 28 17 17 26 17 17 28 17 17 26 17 26 17 26 17 28 17 17 17 17 28 17 17 17 17 17 17
  17 17 17 26 28 28 17 28 17 26 17 17 26 17 17 17 17 17 17 17 28 17 17 17 28 17


sum(pos_AIC == "17")/100 #0.7 #0.76 #0.63 #0.71 #less variation compared with CV


* Correct model proportion (linked to the consistency of the model selection procedure), bigger than 16 with few regressors, consistency we expected to be equal to 1 because we have normality, no correlation. So every time it selects the correct model.
 
 sum(pos_CV > 16)/100 = 1
 
 sum(pos_AIC > 16)/100 = 1

* Average part don't understand well.

# Results for rho=0.2:

```{r,echo=FALSE, results='hide'}
rm(list = ls())

require(mvtnorm)

require(MASS)

### EXERCISE 1 - Simulations and CV ###

## Part a

n = 1000

p = 5

rho = 0.5

mu = rep(1,p)

sigma = rep(0,p^2)

sigma = matrix(data = sigma, ncol = p,nrow = p)

# Autoregressive structure

for (i in 1:p) {
  
  for (j in 1:p) {
    
    
    sigma[i,j] = rho^(abs(i-j))
    
    
  }
  
  
}
sigma
X = mvrnorm(n,mu,sigma)



## Part b

beta = c(3,1.5,0,2,0)

# Signal to noise ratio: how much information we have with respect to the noise

# Statistical literature: reciprocal of CV --> u / sigma

s_n_ratio = mean(X%*%beta) # same result taking the mean out of X directly

# sigma in our case is set to one


## Part c

y_hat = X%*%beta + rnorm(n,0,1) # using signal noise to ratio statistics

## Part d

 set.seed(1)



data = data.frame(cbind(y_hat,X))

colnames(data) = c("y","x1","x2","x3","x4","x5")

ind = 1:1000

index = sample(x = ind,size = 500,replace = F)



train_set = data[index,]

test_set = data[-index,]


# There are 31 possible models: 2^p - 1 = 2^5 - 1 = 31 models 



cv_error = rep(0,31) #want to evaluate 31 models. So I want that one which minimizes the cv_error

aic_values = rep(0,31) #want to evaluate 31 models

#Exhaustive search: 

# One regressor only models

for(i in 1:5) {
  
  
  m_1 = lm(train_set$y ~ train_set[,i+1], data = train_set)
  
  cv_error[i] = mean((test_set$y - (cbind(rep(1,500),test_set[,i+1])%*% m_1$coefficients))^2)
  
  aic_values[i] = -2*logLik(m_1) + 2*3

}


# Two regressors models: from now on using the combn function to evaluate several combination of models with a specific number of regressors



x = c(1,2,3,4,5)

M = combn(x,2)



for(i in 1:10) {
  
  
  m_2 = lm(train_set$y ~ train_set[,M[1,i]+1] + train_set[,M[2,i]+1], data = train_set)
  
  cv_error[i+5] = mean((test_set$y - cbind(rep(1,500),test_set[,M[1,i]+1], test_set[, M[2,i] +1])%*%m_2$coefficients)^2)
  
  aic_values[i+5] = -2*logLik(m_2) + 2*4
}


# Three regressors models

M = combn(x,3)



for(i in 1:10) {
  
  
  m_3 = lm(train_set$y ~ train_set[,M[1,i]+1] + train_set[,M[2,i]+1] + train_set[,M[3,i]+1], data = train_set)
  
  cv_error[i+ 15] = mean((test_set$y - cbind(rep(1,500),test_set[,M[1,i]+1], test_set[, M[2,i] +1],test_set[, M[3,i]+1])%*%m_3$coefficients)^2)
  
  aic_values[i+15] = -2*logLik(m_3) + 2*5
  
}


# Four regressors models

M = combn(x,4)



for(i in 1:5) {
  
  
  m_4 = lm(train_set$y ~ train_set[,M[1,i]+1] + train_set[,M[2,i]+1] + train_set[,M[3,i]+1] + train_set[,M[4,i]+1], data = train_set)
  
  cv_error[i+25] = mean((test_set$y - cbind(rep(1,500),test_set[,M[1,i]+1], test_set[, M[2,i] +1],test_set[, M[3,i]+1],test_set[, M[3,i]+1])%*% m_4$coefficients)^2)
  
  aic_values[i+25] = -2*logLik(m_4) + 2*6
  
}



# Full model 

full_model = lm(train_set$y ~ ., data = train_set)



# Computing the CV_error 

cv_error_full = mean((test_set$y - cbind(rep(1,500), test_set$x1,test_set$x2,test_set$x3,test_set$x4,test_set$x5)%*% full_model$coefficients)^2)

cv_error[31] = cv_error_full

# Computing the AIC values

aic_values[31] = -2*logLik(full_model) + 2*7


min(cv_error) 

which.min(cv_error)

correct_model = lm(train_set$y ~ train_set$x1 + train_set$x2 + train_set$x4, data = train_set)

cv_error_cor = mean((test_set$y - cbind(rep(1,500), test_set$x1,test_set$x2,test_set$x4)%*% correct_model$coefficients)^2)

min(aic_values)

which.min(aic_values) 

AIC(correct_model)

# Calculating the 3 criteria


ind = 1:1000

pos_CV = rep(0,100)

pos_AIC = rep(0,100)


for(z in 1:100) {

y_hat = X%*%beta + rnorm(n,0,1) # you can also use previous formula (i.e. y_hat_eng = data + k*noise )

data = data.frame(cbind(y_hat,X))

colnames(data) = c("y","x1","x2","x3","x4","x5")

index = sample(x = ind,size = 500,replace = F)

train_set = data[index,]

test_set = data[-index,]

cv_error = rep(0,31)

aic_values = rep(0,31)

# One regressor only models

for(i in 1:5) {
  
  
  m_1 = lm(train_set$y ~ train_set[,i+1], data = train_set)
  
  cv_error[i] = mean((test_set$y - (cbind(rep(1,500),test_set[,i+1])%*% m_1$coefficients))^2)
  
  aic_values[i] = -2*logLik(m_1) + 2*3
  
}

# Two regressors models

x = c(1,2,3,4,5)

M = combn(x,2)


for(i in 1:10) {
  
  
  m_2 = lm(train_set$y ~ train_set[,M[1,i]+1] + train_set[,M[2,i]+1], data = train_set)
  
  cv_error[i+5] = mean((test_set$y - cbind(rep(1,500),test_set[,M[1,i]+1], test_set[, M[2,i] +1])%*%m_2$coefficients)^2)
  
  aic_values[i+5] = -2*logLik(m_2) + 2*4
}


# Three regressors models

M = combn(x,3)


for(i in 1:10) {
  
  
  m_3 = lm(train_set$y ~ train_set[,M[1,i]+1] + train_set[,M[2,i]+1] + train_set[,M[3,i]+1], data = train_set)
  
  cv_error[i+ 15] = mean((test_set$y - cbind(rep(1,500),test_set[,M[1,i]+1], test_set[, M[2,i] +1],test_set[, M[3,i]+1])%*%m_3$coefficients)^2)
  
  aic_values[i+15] = -2*logLik(m_3) + 2*5
  
}


# Four regressors models

M = combn(x,4)


for(i in 1:5) {
  
  
  m_4 = lm(train_set$y ~ train_set[,M[1,i]+1] + train_set[,M[2,i]+1] + train_set[,M[3,i]+1] + train_set[,M[4,i]+1], data = train_set)
  
  cv_error[i+25] = mean((test_set$y - cbind(rep(1,500),test_set[,M[1,i]+1], test_set[, M[2,i] +1],test_set[, M[3,i]+1],test_set[, M[3,i]+1])%*% m_4$coefficients)^2)
  
  aic_values[i+25] = -2*logLik(m_4) + 2*6
  
}

# Full model 

full_model = lm(train_set$y ~ ., data = train_set)

full_model$coefficients

cv_error_full = mean((test_set$y - cbind(rep(1,500), test_set$x1,test_set$x2,test_set$x3,test_set$x4,test_set$x5)%*% full_model$coefficients)^2)

cv_error[31] = cv_error_full

aic_values[31] = -2*logLik(full_model) + 2*7

pos_CV[z] = which.min(cv_error)

pos_AIC[z] = which.min(aic_values)

}

# We know that the right position is 17, from 25-30 are difficult model expecially number 28 and 26
#CV is not perfect because is selecting also model 28 and 31
pos_CV 

pos_AIC

# Exact model proportion

sum(pos_CV == "17")/100 #0.5 #0.36  #0.44 #0.45 

sum(pos_AIC == "17")/100 #0.7 #0.76 #0.63 #0.71

# Correct model proportion (linked to the consistency of the model selection procedure)

sum(pos_CV > 16)/100 

sum(pos_AIC > 16)/100

```
So, now we have:

min(cv_error) = 1.0485

correct model = 17th

min AIC=1418.658

correct model change to 31st

# 3 Criteria to choose the best performance:

* Exact model proportion

CV is not perfect because is selecting also model 28 and 31

pos_CV
    31 17 17 17 31 17 31 28 17 31 28 28 31 17 17 28 17 31 28 31 17 17 17 17 17 31 31 28 28 17 17 28 17 28
  17 28 17 17 28 31 31 17 31 28 17 31 28 17 17 28 17 17 17 17 17 17 31 17 28 17 28 28 28 28 28 17 28 17
  28 17 17 31 31 31 17 17 28 17 31 31 31 17 28 28 31 17 31 31 17 17 28 17 31 31 17 31 28 17 28 28
  
  
sum(pos_CV == "17")/100 #0.45 

AIC is also not perfect because is selecting model also 26, 28 and 31

pos_AIC
  
    31 17 26 26 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 26 17 17 17 26 17 17 31 17 17 17 17 28 17
  17 17 26 17 17 17 17 17 17 17 17 17 28 17 17 17 28 17 17 17 17 17 17 17 31 17 17 17 17 17 17 17 17 26
  17 28 17 17 17 17 17 26 17 31 17 17 28 17 17 26 17 17 26 17 26 28 17 17 17 17 17 17 17 17 28 17


sum(pos_AIC == "17")/100 #0.79


* Correct model proportion: in this case we have correlation but still consistency
 
 sum(pos_CV > 16)/100 = 1
 
 sum(pos_AIC > 16)/100 = 1


# Results for rho=0.5: ame code just changing the line 77


So, now we have:

min(cv_error) = 1.056

correct model = 17th

min AIC=1390.42

correct model change to 26th

# 3 Criteria to choose the best performance:

* Exact model proportion

CV is not perfect because is selecting also model 28 and 31

pos_CV
     28 28 17 28 28 17 17 28 17 17 31 17 28 28 31 28 28 31 28 31 28 31 31 28 28 17 17 28 28 31 17 31 17 28
  31 31 28 31 17 28 28 28 17 17 17 17 17 31 28 17 28 28 17 31 28 31 31 31 28 17 31 28 31 17 17 31 17 28
  17 31 28 17 17 28 17 28 28 17 28 17 28 28 17 17 28 28 31 17 28 31 31 17 17 28 17 17 17 17 28 28
  
  
sum(pos_CV == "17")/100 #0.38 #it's even worse compared with lower rho


AIC is also not perfect because is selecting model also 26 and 28

pos_AIC
  
      17 17 17 17 26 26 17 17 17 28 17 17 26 26 17 28 17 17 17 28 17 17 28 17 17 26 17 28 17 17 17 17 26 17
  17 17 28 17 17 17 26 17 17 17 31 17 17 17 26 17 17 17 17 17 17 17 17 17 17 26 17 26 17 26 17 26 17 17
  28 17 26 17 17 28 17 17 26 17 17 17 28 17 17 17 26 28 17 17 17 17 17 17 28 17 26 26 17 26 28 17

sum(pos_AIC == "17")/100 #0.69


* Correct model proportion: in this case we have correlation but we still have consistency
 
 sum(pos_CV > 16)/100 = 1
 
 sum(pos_AIC > 16)/100 = 1


# Results for rho=0.7: ame code just changing the line 77


So, now we have:

min(cv_error) = 1.056

correct model = 17th

min AIC=1390.31

correct model change to 26th

# 3 Criteria to choose the best performance:

* Exact model proportion

CV is not perfect because is selecting also model 28 and 31

pos_CV
     28 28 17 28 28 17 17 28 17 17 31 17 28 28 31 28 28 31 28 31 28 31 31 28 28 17 17 28 28 31 17 31 17 28
  31 31 28 31 17 28 28 28 17 17 17 17 17 31 28 17 28 28 17 31 28 31 31 31 28 17 31 28 31 17 17 31 17 28
  17 31 28 17 17 28 17 28 28 17 28 17 28 28 17 17 28 28 31 17 28 31 31 17 17 28 17 17 17 17 28 28
  
  
sum(pos_CV == "17")/100 #0.37 #it's even worse compared with lower rho


AIC is also not perfect because is selecting model also 26 and 28

pos_AIC
  
     17 17 17 17 26 17 17 17 17 17 17 17 26 26 17 28 17 17 17 28 17 17 28 17 17 26 17 28 17 17 17 17 26 17
  17 17 28 17 17 17 26 17 17 17 31 17 17 17 26 17 17 17 17 17 17 17 17 17 17 26 17 26 17 26 17 26 17 17
  28 17 17 17 17 28 17 17 17 17 17 17 28 17 17 17 26 28 17 17 17 17 17 17 17 17 26 26 17 26 28 17


sum(pos_AIC == "17")/100 #0.74 


* Correct model proportion: in this case we have correlation but we still have consistency
 
 sum(pos_CV > 16)/100 = 1
 
 sum(pos_AIC > 16)/100 = 1
 
#  Summary:
 
CV: for all different values of rho, it gave us the 17h model as the one which has the minimum CV error. Although, this error was increasing and the proportion of 17 was decreasing.

AIC: for each value of rho, it gave us different choices of models, 26h for example. Although, as we can se the pos_AIC for each rho has the bigger proportion of the model 17th.

So, to sum up, even with correlation, the AIC is better method than CV to choose the best model.


### ===================== EX.3 =============================================

## ========================================================================

```{r , echo=FALSE}
### ===================== Set working space ========================================



# Clear objects

rm(list = ls())

# Clear console

cat("\014")

# Set working directory

setwd("/Users/TaliaKimber/Documents/Unige/2_MA/Model_Selection/Practical4")



par(mfrow = c(1,1))



## a)

# Data

load("data_leukemia_reduced.Rda")

dat <- data_leukemia_reduced

attach(dat)

# GLM fit with one predictor

fit.glm = glm(formula = y ~ V457,family = "binomial")

summary(fit.glm) 



## b)

y.hat <- fit.glm$fitted

c <- 0.5

for (i in 1: length(y)){

  if (y.hat[i] >= c)

    y.hat[i] = 1

  else y.hat[i] = 0

}

TP <- numeric(1)

FP <- numeric(1)

TN <- numeric(1)

FN <- numeric(1)



for (i in 1: length(y)){

  if (y.hat[i] == 1 & y[i] == 1){

    TP <- TP + 1 # True Positive

  }

  else if (y.hat[i] == 1 & y[i] == 0){

    FP <- FP + 1 # False Positive

  }

  else if (y.hat[i] == 0 & y[i] == 0){

    TN <- TN + 1 # True Negative

  }

  else if (y.hat[i] == 0 & y[i] == 1){

    FN <- FN + 1 # False Negative

  }

}



length(y) == TP + FP + TN + FN



## c)

# Cut-off grid

c.seq <- seq(0,1,length.out = 10)

# Predicted values : number of rows is the number of observations

# number of columns is the number of c's

y.hat.seq <- matrix(NA, nrow = length(y), ncol = length(c.seq))

# All columns start with the fitted values of GLM. Then use threshold

y.hat.seq[, 1:length(c.seq)] <- fit.glm$fitted



for (k in 1:length(c.seq)){

  for (i in 1: length(y)){

    if (y.hat.seq[i,k] >= c.seq[k])

      y.hat.seq[i,k] = 1

    else y.hat.seq[i,k] = 0

  }

}



# Define the proportion of TP and FP per values of c

TP.seq <- matrix(0, nrow = 1, ncol = length(c.seq))

FP.seq <- matrix(0, nrow = 1, ncol = length(c.seq))

for (k in 1:length(c.seq)){

  for (i in 1: length(y)){

    if (y.hat.seq[i,k] == 1 & y[i] == 1){

      TP.seq[k] <- TP.seq[k] + 1 # True Positive

    }

    else if (y.hat.seq[i,k] == 1 & y[i] == 0){

      FP.seq[k] <- FP.seq[k] + 1 # False Positive

    }

  }

}





plot(y = TP.seq * 100/72, x = FP.seq* 100/72, type = "line", main ="ROC Curve",

     xlab = "False Positive rate, P(FP) % ", ylab = "True Positive rate, P(TP) % ", col = 'blue')

abline(0, 1, col= "black")





## d)

require("pROC")

roc(y,V457, percent =T, plot = T, smooth = T)





detach(dat)

```

