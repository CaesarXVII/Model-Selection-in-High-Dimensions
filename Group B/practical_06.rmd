---
title: "Practical_6"
author: "Alexander Maslev, Hanxiong Wang, Minyoung Lee"
date: "2018?? 4?? 9??"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## EXERCISE 1

```{r cars}
summary(cars)
```

## EXERCISE 2
### PC Simple Algorithm
```{r, warning=FALSE,echo=FALSE,results=FALSE}
# Basic setting
library(MASS)
set.seed(11)
p<-10
rho<-0.5
n<-1000
sigma<-matrix(0,p,p)
for(i in 1:p){for(j in 1:p){
  sigma[i,j]<-rho^abs(i-j)}}

Mu<-rep(0,10) # location vector
X<-mvrnorm(n , Mu, sigma)
colnames(X)<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9","X10")
beta<-c(3,1.5,0,2,rep(0,6))
e<-rnorm(n, mean = 0, sd = 1)
Y_hat<-X%*%beta+e

```

### a) First variable to enter the algorithm based on the correlation(Y and Xs)
We can not compute partial correlation for the first stage because we don't have variable to conditioning on. Thus We take correlation to select the first variable to enter the model. 
```{r}
var_ind<-which.max(cor(Y_hat,X)) 
var_ind # initial setting

var_name<-colnames(X)[which.max(cor(Y_hat,X))]
var_name 
```
The variable that we will choose for the first variable to enter is X1 because it has highest correlation with Y.

### b) Partial correlation of order 1. 
```{r}

Mm<-X[,-var_ind]
Xc<-X[,var_ind]

par_cor<-rep(0,ncol(Mm))
for(j in 1:ncol(Mm)){
  H<-Xc%*%solve(t(Xc)%*%Xc)%*%t(Xc)
  e<-(diag(n)-H)%*%Y_hat
  I<-diag(n)
  par_cor[j]<-t(e)%*%(I-H)%*%Mm[,j]/sqrt((t(e)%*%e)%*%(t(Mm[,j]%*%(I-H)%*%Mm[,j])))
}

var_name<-c(var_name,colnames(Mm)[which.max(par_cor)])

Fisher_z<-1/2*log((1+par_cor[which.max(par_cor)])/(1-par_cor[which.max(par_cor)]))
sqrt(n-1-3)*abs(Fisher_z)>qnorm(1-0.05/2)

colnames(Mm)[which.max(par_cor)]


```
We compute the partial correlation given that we choose the variable X1. We compute partial correlation of order 1 and did hypothesis test to check the inclusion of the variable. Ho : $\rho_{X_{j}Y,X_{c}} = 0$ is rejected if the logic is TRUE. Based on the hypothesis test, we include X4 as the second variable to the model.

### c) partial correlations of higher order until converge.
```{r}
var_name<-colnames(X)[which.max(cor(Y_hat,X))]
var_name 
var_ind<-which.max(cor(Y_hat,X))
Mm<-X[,-var_ind]
Xc<-X[,var_ind]
for (p in 2:ncol(X)){
  
  par_cor<-rep(0,ncol(Mm))
  for(j in 1:ncol(Mm)){
    H<-Xc%*%solve(t(Xc)%*%Xc)%*%t(Xc)
    e<-(diag(n)-H)%*%Y_hat
    I<-diag(n)
    par_cor[j]<-t(e)%*%(I-H)%*%Mm[,j]/sqrt((t(e)%*%e)%*%(t(Mm[,j]%*%(I-H)%*%Mm[,j])))
    Fisher_z<-1/2*log((1+par_cor[j])/(1-par_cor[j]))
    Hypo_test[j]<-sqrt(n-9-3)*abs(Fisher_z)
  }
  Fisher_z<-1/2*log((1+par_cor[which.max(par_cor)])/(1-par_cor[which.max(par_cor)]))
  
  
  if (sqrt(n-p-3)*abs(Fisher_z)<=qnorm(1-0.05/2)) break 
  
  var_ind<-which.max(par_cor)
  var_name<-c(var_name,colnames(Mm)[which.max(par_cor)])
  Mm<-Mm[,-var_ind]
  Xc<-cbind(Xc,Mm[,var_ind])
            
}
p
var_name

```
We implement the algorithm that will find variables that we choose and the "m" which will meet the stopping condition : $M_{m-1}=M_{m}$. We stop when m = 4 and we select the variables (X1, X4, X2). This is exact model as we have $\beta = [3 1.5 0 2 rep(0,6)].  Even, the order of entering the model is same as the order of the size of the coefficient. 

