---
title: "Practical Intro to RMD and Github"
author: "Cesare Miglioli"
date: "15 febbraio 2022"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercise 1

## Part (a)

### R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

### Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

## Part (b)

### Histogram of the sepal width of Iris Setosa

```{r, eval=FALSE, echo=FALSE}

hist(iris$Sepal.Width[iris$Species == "setosa"])

```

```{r, echo=FALSE, fig.width=5,fig.height=3}

hist(iris$Sepal.Width[iris$Species == "setosa"], main = "Histogram for Iris Setosa")

```

## Part (c)

### Conditional probability of observing an Iris Virginica given that the sepal width is greater than 3:

#### In line formula

$P(\; virginica / \; sepal.width > 3) = \frac{P(virginica \; \& \; sepal.width > 3)}{P(sepal.width > 3)} = 0.254$  

#### Latex environment

\begin{equation*}
	P(\; virginica / \; sepal.width > 3) = \frac{P(virginica \; \& \; sepal.width > 3)}{P(sepal.width > 3)} = 0.254
\end{equation*}

#### Evaluation of the formula

```{r}

sub_joint = subset(iris,iris$Species == "virginica" & iris$Sepal.Width > 3)

sub_marg = iris$Sepal.Width[iris$Sepal.Width > 3]

result = dim(sub_joint)[1]/length(sub_marg)

result

```

# Exercise 3 

## Part (a)

Run the commands already present in *practical_02.rmd* (i.e. this file) to load the dataset and retrieve the important variables.

```{r, results='hide', warning=FALSE}

require(foreign)  # install foreign package if you do not have it yet

# See section 1.6.2 e-book for information on the dataset.

dat = read.spss("Zambia.SAV", add.undeclared.levels = "no")

# dat = read.spss("Zambia.SAV")

# Construct system matrix

# The idea behind this exercise is to be aware that data cleaning is most of the times the real issue 
# with a real problem. It is sensitive to say that 80% of the work is cleaning and only 20% is modeling.

# Extract response variable i.e. HW70 Height for age standard deviation (according to WHO)
y = dat$HW70
y[y == 9996] = NA
y[y == 9997] = NA
y[y == 9998] = NA
y[y == 9999] = NA

# Revert tranformation (i.e. z-score)
y = y/100

# Variable 1: The calculated months of breastfeeding gives the duration of breastfeeding
x1 = dat$M5
x1[x1 == 94] = 0
x1[x1 == 97] = NA
x1[x1 == 98] = NA
x1[x1 == 99] = NA
x1[x1 > 40] = NA

# Variable 2: Age in months of the child
x2 = dat$HW1

# Variable 3: Age of the mother at birth
x3 = dat$V012 - dat$B8
x3[x3>45] = NA

# Variable 4: Body mass index (BMI) of the mother
x4 = dat$V445

x4 = x4/100  # no sense without this division

# Variable 5: Height of the mother in meters
x5 = dat$V438
x5[x5 == 9998] = NA
x5[x5 == 9999] = NA
x5[x5 < 1300] = NA
x5[x5 > 1900] = NA

x5 = x5/1000  # it was in mm, we need to transform from original

# Variable 6: Weight of the mother in kilograms
x6 = dat$V437

x6=x6/10 # we need to go back to Kg

# Variable 7: De facto region of residence

# Creating dummies (i.e. indicator functions) for each level of an existing factor enables
# to check the coefficients of each level in a possible future model estimation

x7 = as.factor(dat$V101)


x7 = model.matrix(~x7-1)

dim(x7)

# Variable 8: Mother highest education level attended
x8 = as.factor(dat$V106)
x8 = model.matrix(~x8-1)

dim(x8)

# Variable 9: Wealth index factor score
x9 = dat$V191

# Variable 10: Weight of child at birth given in kilograms with three implied decimal places
x10 = dat$M19
x10[x10 == 9996] = NA
x10[x10 == 9997] = NA
x10[x10 == 9998] = NA
x10[x10 == 9999] = NA
x10 = x10/1000

# Variable 11: Child Sex
x11 = dat$B4

# Variable 12: Preceding birth interval is calculated as the difference in months between the current birth and the previous birth
x12 = dat$B11
x12[x12 > 125] = NA

# Variable 13: Drinking Water
x13 = dat$V113
x13 = model.matrix(~x13-1)
x13 = x13[,c(2,3,4,8,9,13,17,18)]

dim(x13)

levels(x13)

mat.sys = na.omit(cbind(y,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13))
dim(mat.sys)[2]


# Number of regressor
p = dim(mat.sys)[2]

# Construct X and Y
y = mat.sys[,1]
X = mat.sys[,2:p]

# Create a dataframe

data_zambia = cbind(y,X)

data_zambia = data.frame(data_zambia)

```

## Part (b)

Associate proper names to each variable (hint: look at the comments in the r chunk).

```{r, results='hide'}

colnames(data_zambia) = c("Height for age sd", "Breastfeeding duration (months)","Age of the child (months)", "Age of the mother (years)", "BMI mother", "Heigth mother (meter)", "Weight mother (kg)", "Region:Central", "Region:Copperbelt", "Region:Eastern", "Region:Luapula", "Region:Lusaka", "Region:Northern", "Region:Northwestern", "Region:Southern", "Region:Western", "Ed:No education", "Ed:Primary", "Ed:Secondary", "Ed:Higher", "Wealth index factor score", "Child weight at birth (kg)", "Child sex", "Interval between births","Water:Piped into dwelling", "Water:Piped to yard/plot", "Water:Public tap/standpipe", "Water:Protected well", "Water:Unprotected well", "Water:River/dam/lake/ponds/stream/canal/irrigation channel", "Water:Bottled water", "Water:Other")
                    

```


## Part (c)

Perform a linear regression on all the available variables.

```{r, eval=FALSE}

attach(data_zambia)

lm_zambia = lm(`Height for age sd` ~ . -`Region:Central`- `Ed:No education`, data = data_zambia)

# We take off two levels to avoid multicollinearity. This should always be done when you create dummies.
summary(lm_zambia) # read the output understand the benchmark of the factor

lm_zambia_full = lm(`Height for age sd` ~ . , data = data_zambia)

summary(lm_zambia_full) #here it is R who choses the benchmark for the factors (i.e. NA variables)

detach(data_zambia)

```



## Part (d)

Reduce the number of covariates (e.g. using the t-test) and add some interactions. Perform a linear regression on the new dataset.

```{r, results='hide'}

attach(data_zambia)

# Eliminate variables with t-test in a stepwise manner (fixed alfa = 0.05 in this case)

model_zambia_reduced = lm(`Height for age sd` ~ ., data = data_zambia[,c(1:2,4,9:16,21:23)])


summary(model_zambia_reduced) # notice what is happening to the age of the mother variable 


# Introduce one interaction in the reduced model. We start with the childsex factor.

model_zambia_int = lm(`Height for age sd` ~ . + `Breastfeeding duration (months)`*`Child sex`, data = data_zambia[,c(1:2,4,9:16,21:23)])


summary(model_zambia_int) #We take out the interaction from the model as it is not significant

#### Remember: the hierarchical effect states that anytime you add an interaction also the marginal effects

#### should be part of your model

detach(data_zambia)

```

Other available procedures for a first model selection in this specific case:

```{r, eval=FALSE}

# (1) VIF (variance inflation factor) for avoiding multicollinearity, 

# (2) Automatic Stepwise procedures (e.g. forward and backward) 

# (3) Exhaustive search (See practical 3 exercises)

# Example with an automatic stepwise procedure

help("step")

stepwise_procedue = step(lm_zambia_full,direction = "backward") #or forward

# This procedure evaluates, given a criterion, a sequence of variables stopping when
# the criterion is increasing

```



## Part (e)

Analyse your chosen estimated model with a residual analysis (e.g. residuals vs fitted plot, normal QQ plot etc.).

```{r}

# Validate your model looking at residuals vs fitted plot and normal QQ plot

plot(model_zambia_reduced, which = 1)  # Residuals vs fitted: no particular structure

plot(model_zambia_reduced, which = 2) 

# Normal QQ plot: We observe right tail which is not compatible with a normal assumption

```


# Exercise 4 

Certain factors that can affect a childhood outlook (prognosis) are called prognostic factors. They help doctors decide whether a child with leukemia should receive standard treatment or more intensive treatment. Prognostic factors seem to be more important in acute lymphocytic leukemia (ALL) than in acute myelogenous leukemia (AML). See <https://www.cancer.org/cancer/leukemia-in-children/detection-diagnosis-staging/prognostic-factors.html> for a detailed explanation.

The *leukemia* dataset contains gene expression measurements on 72 leukemia patients: 47 ALL (i.e. acute lymphocytic leukemia) and 25 AML (i.e. acute myelogenous leukemia). These data arise from the landmark of Golub et al. 1999 Science paper and exhibit an important statistical challenge because $p >> n$ as we deal with 72 patients and 7128 measurements. 

#### Exercises 

```{r, message=F, echo=F}
show_solution <- T # set to T to show the solutions on these exercises.
solution_header <- ifelse(show_solution, "<div>", "<div style='display:none'>")
```


- Load the package SIS in your R environment. Type both *data("leukemia.train")* and *data("leukemia.test")* in the console window to load the data.

```{r results="asis", echo=F}
cat(solution_header)
```
```{r, eval=T}

require(SIS)

data("leukemia.train")

data("leukemia.test")

```
</div>


- Create the response variable y according to the number of ALL and AML patients. In the same fashion create the matrix X of independent variables by merging the two datasets.

```{r results="asis", echo=F}
cat(solution_header)
```
```{r, eval=T}

full = rbind(leukemia.train,leukemia.test)

y = full[,7130]

X = full[,-7130]

X = as.matrix(X)

```
</div>


- Choose the correct exponential family for this situation and perform a GLM on the data. Comment on the results that you obtain. 

<!-- Since p>>n there are problems -->

```{r results="asis", echo=F}
cat(solution_header)
```
```{r, eval=F}

model_glm = glm(formula = y ~ X,family = "binomial")


summary(model_glm)  #singularity issues in the IWLS algorithm of GLM. It is impossible to invert the matrix.

# The binary Lasso is a possible way to solve the issue and have an actual estimate. See glmnet package.

```
</div>


<!-- We can choose here if already talk about the binary lasso as a possible solution-->
