---
title: "CV and AIC"
author: "Cecilia Galvan and Nensi Kopellaj"
date: "05 03 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bspec)
library(MASS)
library(base)
library(leaps)
library(caret)
library(DAAG)
```

# Simulations and CV

## (a)

```{r a}
n <- 1000
p <- 5
mu <- rep(0, length = p)
sigma <- diag(p)
X <- mvrnorm(n, mu, sigma)
```

## (b)

Signal to noise ratio definition: https://en.wikipedia.org/wiki/Signal-to-noise_statistic

```{r b}
b <- c(3,1.5,0,2,0)
signal <- X %*% t(t(b))
noise <- mvrnorm(n, 0, 1)
ratio <- (mean(signal)-mean(noise)) / (sd(signal)+sd(noise))
ratio
```

## (c)

```{r c}
y_hat <- X %*% t(t(b)) + mvrnorm(n, 0, 1)
```

## (d)

```{r d}
index <- sample(1:n,n/2)
train.data <- y_hat[index,]
test.data <- y_hat[-index,]

x <- X[index,]
b_mle <- solve(t(x) %*% x) %*% t(x)%*%train.data
b_mle
```

Using the squared loss function, we compute the CV score on all possible models, which are 31. We consider p = 1,...,5.

```{r p5}
# ModÃ¨le complet: p = 5
x <- X[index,]
b_mle <- solve(t(x) %*% x) %*% t(x)%*%train.data
y_test_5 <- X[-index,] %*% b_mle
loss_fct_test_5 <- mean((y_hat[-index,] - y_test_5)^2)
loss_fct_test_5

x <- X[-index,]
b_mle <- solve(t(x) %*% x) %*% t(x)%*%test.data
y_test_5 <- X[index,] %*% b_mle
loss_fct_test_5_CV <- mean((y_hat[index,] - y_test_5)^2)
loss_fct_test_5_CV
```

CV scores are low for the model taking all the variables

```{r p4}
loss_fct_test_4 <- c(1:5)
loss_fct_test_4_CV <- c(1:5)
for (i in 1:5) {
  x <- X[index,-i]
  b_mle <- solve(t(x) %*% x) %*% t(x)%*%train.data
  
  loss_fct_test_4[i] <- mean((y_hat[-index,] - (X[-index,-i] %*% b_mle ))^2)
  
  x_CV <- X[-index,-i]
  b_mle_CV <- solve(t(x_CV) %*% x_CV) %*% t(x_CV)%*%test.data
  
  loss_fct_test_4_CV[i] <- mean((y_hat[index,] - (X[index,-i] %*% b_mle_CV ))^2)
}
loss_fct_test_4
loss_fct_test_4_CV
```

We know that models without either X3 or X5 have lowest error, we therefore try a model without both of them

```{r p3}
loss_fct_test_3 <- matrix(nrow = 5, ncol = 5)
loss_fct_test_3_CV <- matrix(nrow = 5, ncol = 5)
for (i in 1:5) {
  for (j in 1:5){
    x <- X[index,-c(i,j)]
    b_mle <- solve(t(x) %*% x) %*% t(x)%*%train.data
    
    loss_fct_test_3[i,j] <- mean((y_hat[-index,] - (X[-index,-c(i,j)] %*% b_mle ))^2)
    
    
    x_CV <- X[-index,-c(i,j)]
    b_mle_CV <- solve(t(x_CV) %*% x_CV) %*% t(x_CV)%*%test.data
    
    loss_fct_test_3_CV[i,j] <- mean((y_hat[index,] - (X[index,-c(i,j)] %*% b_mle_CV ))^2)
  }
}
loss_fct_test_3
loss_fct_test_3_CV
```

Having a model without X3 and X5 has a low CV score.

```{r p2, error=TRUE}
# loss_fct_test_2 <- matrix(nrow = 5, ncol = 5)
for (i in 1:5) {
  for (j in 1:5){
    x <- X[index,c(i,j)]
    b_mle <- solve(t(x) %*% x) %*% t(x)%*%train.data
    
    # loss_fct_test_2[i,j] <- mean((y_hat[-index,] - (X[-index,] %*% b_mle ))^2)
  }
}
```

The matrix (X'X) can't be inverted => 'no solution'

```{r p1}
loss_fct_test_1 <- c(1:5)
loss_fct_test_1_CV <- c(1:5)
for (i in 1:5) {
  x <- X[index,i]
  b_mle <- solve(t(x) %*% x) %*% t(x)%*%train.data

  loss_fct_test_1[i] <- mean((y_hat[-index,] - (X[-index,i] %*% b_mle ))^2)
  
  
  x_CV <- X[-index,i]
  b_mle_CV <- solve(t(x_CV) %*% x_CV) %*% t(x_CV)%*%test.data
  
  loss_fct_test_1_CV[i] <- mean((y_hat[index,] - (X[index,i] %*% b_mle_CV ))^2)
}
loss_fct_test_1
loss_fct_test_1_CV
```

All CV scores are higher than the previous models.

The model with the lower CV score is the one with the 5 variables. However, we can take out X3 and X5 without a big increase in error.

## (e)
```{r e}
combinations <- c(1:100)
for (i in 1:100) {
  combinations[i] <- factorial(100) / (factorial(i) * factorial(100-i))
}
poss_comb <- sum(combinations)
poss_comb
```

We have 1.267651e+30 possible combinations, without taking into account interactions, non linearity, ... .

It takes too much time to write explicitly all the models and it will also increase the computational time.


# Simulations and AIC
## (a)
```{r 2a}
y_hat <- X %*% t(t(b)) + mvrnorm(n, 0, 1)
```

## (b)

We have that p = 5, it means that all variables should be taken into account

```{r 2b, error=TRUE}
our_aic <- sum((y_hat[-index,] - X[-index,] %*% b_mle)^2) + 2*p

# For comparison
DATA <- data.frame(y_hat,X)
reg <- lm(y_hat~., data = DATA[-index,])
AIC(reg)
```

We couldn't find the error in our formula...

## (c)
Same conclusion as in point (e), exercise 1: too long to compute all possible models.

Also, we don't have the betas.


# Real Data Application

```{r 3a}
load('malnutrion_zambia_cleaned.Rda')
str(data_zambia)
plot(data_zambia[,c(1:7,21,22,24)])
```

BMI is a combination of weight and height, so to avoid to have twice the same information, we'll take out this variable.

Our dataset becomes:
```{r dat}
dat <- data_zambia[,c(1:4,6,7,21,22,24)]

plot(dat)
```

This plot is not very informative...

### CV

For CV results, check Rmarkdown code (option of chunk: include=FALSE)

```{r cv, include=FALSE}
reg_lm <- lm(`Height for age sd` ~ ., data = dat)
cv.lm(data = dat, reg_lm, m = 2) # 2 fold cross-validation
```

"Age of the child (months)" and "Interval between births" seem to be not significant. Because of the p-value, we take out "Interval between births".

```{r cv2, include=FALSE}
model2 <- lm(`Height for age sd` ~ `Breastfeeding duration (months)` + `Age of the child (months)` + `Age of the mother (years)` + `Heigth mother (meter)` + `Weight mother (kg)` + `Wealth index factor score` + `Child weight at birth (kg)`, data = dat)
cv.lm(data = dat, model2, m = 2)
```

"Age of the child (months)" is still not significant, so we take it out.

```{r cv3, include=FALSE}
model3 <- lm(`Height for age sd` ~ `Breastfeeding duration (months)` +  `Age of the mother (years)` + `Heigth mother (meter)` + `Weight mother (kg)` + `Wealth index factor score` + `Child weight at birth (kg)`, data = dat)
cv.lm(data = dat, model3, m = 2)
```

Based on a CV analysis, our final model will contain the following variables:

  * Breastfeeding duration (months)
  * Age of the mother (years)
  * Heigth mother (meter)
  * Weight mother (kg)
  * Wealth index factor score
  * Child weight at birth (kg)


### AIC

```{r aic}
stepAIC(reg_lm)
```

Based on AIC analysis, we shouldn't take out any variable. 

However, the AIC score doesn't increase a lot in our opinion when "Age of the mother (years)", "Interval between births" and "Age of the child (months)" are not considered in the model.

The model that we propose is the one containing the following variables:

  * Breastfeeding duration (months)
  * Heigth mother (meter)
  * Weight mother (kg)
  * Wealth index factor score
  * Child weight at birth (kg)


We believe that those results are consistent with the theory:

 * Cross-validation: "technique for assessing how the results of a statistical analysis will generalize to an independent data set" (source: Wikipedia)
 * AIC: "relative quality of statistical models for a given set of data" (source: Wikipedia)

CV method will help us recognize the "more useful" variables to make a good out-of-sample prediction. AIC will tell us if the variables are correctly explaining the dataset.